# üéØ WEEK 7 IMPLEMENTATION PLAN: CRITICAL FIXES & DEMO PREPARATION
**Repository:** `L1quidDroid/Internship_C` (develop branch)  
**Goal:** Fix 3 critical blockers + deliver working demo by Friday  
**Timeline:** Monday Jan 5 ‚Üí Friday Jan 9, 2026

***

## üìã EXECUTIVE SUMMARY

### **Current Status: 75% Complete**

| Feature | Status | Blocker? |
|---------|--------|----------|
| Agent Enrollment | ‚úÖ 100% | No |
| PDF Reporting | ‚ö†Ô∏è 85% | Yes (performance) |
| Attack Tagging | ‚ùå 40% | Yes (not integrated) |
| Branding | ‚è∏Ô∏è 0% | No (deferred) |

### **3 Critical Blockers Identified**

1. üî¥ **Orchestrator Not Integrated** ‚Üí SIEM tagging doesn't auto-trigger
2. üî¥ **Slow Report Data Gathering** ‚Üí 600ms overhead, breaks <8s target
3. üî¥ **Security Risk** ‚Üí GitHub publishing exposes client data

### **This Week's Mission**

Fix all 3 blockers by Tuesday, test Wednesday, demo Friday.

***

# üö® CRITICAL BLOCKER #1: ORCHESTRATOR NOT INTEGRATED

## ‚ùå PROBLEM

**Symptom:** SIEM tagging code exists but never runs during operations.

**Root Cause:**  
Your `SIEMIntegration` class in `plugins/orchestrator/app/webhook_service.py` is **standalone code** with no Caldera lifecycle hooks. When you run operations in the GUI, Caldera doesn't know to call your tagging function.

**Current (Broken) Architecture:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Caldera Operation Runs              ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Techniques execute              ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Operation finishes              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ ‚ùå NO TAGGING HAPPENS           ‚îÇ ‚Üê Nothing calls your code!
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Your SIEMIntegration Class (Orphaned):
  ‚îî‚îÄ‚îÄ tag_elk_alerts()  ‚Üê Exists but never called
```

**Evidence to Check:**
```bash
# Your code probably looks like this:
cd ~/caldera/plugins/orchestrator/app
grep -A 20 "class SIEMIntegration" webhook_service.py

# Output shows a class with methods, but no hook registration
```

***

## ‚úÖ SOLUTION: CREATE ORCHESTRATOR HOOK

### **What to Do:** Register your class with Caldera's event system

**Step 1: Create `plugins/orchestrator/hook.py`** (30 min)

```bash
# Navigate to orchestrator plugin
cd ~/caldera/plugins/orchestrator

# Create hook file
touch hook.py
code hook.py  # Or vim/nano
```

**Step 2: Write Hook Registration Code**

Copy this **complete implementation**:

```python
# plugins/orchestrator/hook.py
"""
Orchestrator Plugin Hook - Registers SIEM tagging lifecycle hooks.

This file is automatically loaded by Caldera on startup.
It registers your SIEMIntegration class to receive operation.completed events.
"""

from plugins.orchestrator.app.webhook_service import SIEMIntegration

# Plugin metadata (required by Caldera)
name = 'Orchestrator'
description = 'Attack tagging and SIEM integration for purple team operations'
address = None  # No GUI component
access = None   # No special permissions

async def enable(services):
    """
    Called when Caldera starts. Registers event subscriptions.
    
    Args:
        services (dict): Caldera core services
            - data_svc: Database access
            - event_svc: Event subscription system
            - logger: Logging instance
    """
    logger = services.get('logger')
    event_svc = services.get('event_svc')
    
    logger.info('üîß Initializing Orchestrator plugin...')
    
    # Create your SIEM integration service
    siem_integration = SIEMIntegration(services)
    
    # ‚úÖ CRITICAL: Subscribe to operation completion events
    if event_svc:
        await event_svc.observe_event(
            callback=siem_integration.on_operation_completed,  # Your method
            exchange='operation',  # Listen to operation events
            queue='completed'      # Specifically: completed operations
        )
        logger.info('‚úÖ Orchestrator: Registered operation.completed hook')
        logger.info('   ‚Üí SIEM tagging will now auto-trigger on operation finish')
    else:
        logger.error('‚ùå event_svc not available‚Äîtagging will not work!')
    
    # Store reference for cleanup
    services['siem_integration'] = siem_integration
    
    logger.info('‚úÖ Orchestrator plugin loaded successfully')

async def disable(services):
    """
    Called when Caldera shuts down. Cleanup resources.
    """
    logger = services.get('logger')
    logger.info('üîß Disabling Orchestrator plugin...')
    
    # Add cleanup logic here if needed
    # (e.g., close connections, flush buffers)
    
    logger.info('‚úÖ Orchestrator plugin disabled')
```

**Step 3: Update `webhook_service.py`** (30 min)

Add the event handler method to your `SIEMIntegration` class:

```python
# plugins/orchestrator/app/webhook_service.py

class SIEMIntegration:
    def __init__(self, services):
        """
        Initialize SIEM integration service.
        
        Args:
            services (dict): Caldera services
        """
        self.services = services
        self.data_svc = services.get('data_svc')
        self.log = services.get('logger')
        # ... rest of your __init__ code
    
    async def on_operation_completed(self, event):
        """
        Event handler: Called automatically when operation finishes.
        
        This is the "magic" method that Caldera calls via hook.py.
        
        Args:
            event (dict): Event payload containing:
                - 'operation': Operation object (or None)
                - 'timestamp': Event timestamp
        
        Workflow:
            1. Validate operation exists and is finished
            2. Extract operation ID
            3. Call tag_elk_alerts() to tag SIEM
            4. Log success/failure
        """
        operation = event.get('operation')
        
        # Validate operation
        if not operation:
            self.log.debug('on_operation_completed called with no operation')
            return
        
        if operation.state != 'finished':
            self.log.debug(f'Skipping tagging for non-finished operation: {operation.state}')
            return
        
        try:
            self.log.info(f'üè∑Ô∏è Auto-tagging ELK alerts for operation: {operation.name} ({operation.id[:8]}...)')
            
            # Call your existing tagging function
            await self.tag_elk_alerts(operation.id)
            
            self.log.info(f'‚úÖ ELK tagging complete for operation: {operation.name}')
            
        except Exception as e:
            # ‚úÖ CRITICAL: Log error but don't raise (event handlers must not crash)
            self.log.error(f'‚ùå ELK tagging failed for operation {operation.id}: {e}', exc_info=True)
    
    async def tag_elk_alerts(self, operation_id):
        """
        Your existing tagging logic (keep as-is).
        
        This method is now called by on_operation_completed().
        """
        # ... your existing code ...
        pass
```

**Step 4: Test Integration** (15 min)

```bash
# Start Caldera
cd ~/caldera
source venv/bin/activate
python server.py --insecure

# Watch logs in separate terminal
tail -f logs/caldera.log | grep -i orchestrator

# Expected output:
# üîß Initializing Orchestrator plugin...
# ‚úÖ Orchestrator: Registered operation.completed hook
# ‚úÖ Orchestrator plugin loaded successfully

# If you see "event_svc not available" ‚Üí PROBLEM, check Caldera version
```

**Step 5: Test Auto-Tagging** (15 min)

```bash
# In Caldera GUI:
# 1. Create operation
# 2. Run techniques
# 3. Stop operation

# Watch logs:
tail -f logs/caldera.log | grep "üè∑Ô∏è"

# Expected:
# üè∑Ô∏è Auto-tagging ELK alerts for operation: Test Op (abc123...)
# ‚úÖ ELK tagging complete for operation: Test Op
```

**Step 6: Commit Changes**

```bash
git add plugins/orchestrator/hook.py
git add plugins/orchestrator/app/webhook_service.py
git commit -m "fix(orchestrator): integrate SIEM tagging into Caldera lifecycle

- Created hook.py with event subscription
- Added on_operation_completed() handler to SIEMIntegration
- SIEM tagging now auto-triggers when operations finish
- Fixes: #1 Critical blocker (tagging not integrated)"

git push origin develop
```

***

### **Success Criteria**

- ‚úÖ `hook.py` exists in `plugins/orchestrator/`
- ‚úÖ Caldera logs show "Orchestrator: Registered operation.completed hook"
- ‚úÖ Running operation ‚Üí logs show "üè∑Ô∏è Auto-tagging ELK alerts..."
- ‚úÖ No manual API calls needed to trigger tagging

***

# üö® CRITICAL BLOCKER #2: SLOW REPORT DATA GATHERING

## ‚ùå PROBLEM

**Symptom:** PDF generation takes 5-6 seconds, missing your <8s target with little safety margin.

**Root Cause:**  
Your `ReportAggregator` makes **4 separate HTTP calls** to Caldera's REST API to gather operation data. Even to `localhost`, each HTTP call has 100-200ms overhead.

**Current (Slow) Architecture:**
```python
# Your current code (estimated):
class ReportAggregator:
    async def get_operation_data(self, operation_id):
        # ‚ùå HTTP call #1: Get operation
        response1 = await aiohttp.get('http://localhost:8888/api/v2/operations/' + operation_id)
        operation = response1.json()  # 150ms overhead
        
        # ‚ùå HTTP call #2: Get links
        response2 = await aiohttp.get('http://localhost:8888/api/v2/operations/' + operation_id + '/links')
        links = response2.json()  # 150ms overhead
        
        # ‚ùå HTTP call #3: Get agents
        response3 = await aiohttp.get('http://localhost:8888/api/v2/agents')
        agents = response3.json()  # 150ms overhead
        
        # ‚ùå HTTP call #4: Get facts
        response4 = await aiohttp.get('http://localhost:8888/api/v2/facts')
        facts = response4.json()  # 150ms overhead
        
        # Total overhead: 600ms (plus JSON serialization)
```

**Why It's Slow:**
- HTTP overhead (TCP handshake, headers, serialization)
- JSON parsing overhead
- Network stack overhead (even to localhost)
- Total: **600-800ms wasted per report**

***

## ‚úÖ SOLUTION: USE INTERNAL `data_svc`

### **What to Do:** Query Caldera's database directly (5-10ms per query)

**Step 1: Locate Your `ReportAggregator` Code** (5 min)

```bash
# Find where you aggregate data
cd ~/caldera/plugins/reporting
grep -r "aiohttp\|requests\|http://localhost:8888" app/

# Common locations:
# - app/report_aggregator.py
# - app/pdf_generator.py
# - app/report_svc.py
```

**Step 2: Rewrite to Use `data_svc`** (1 hour)

**Option A: If you have separate `report_aggregator.py`:**

```python
# plugins/reporting/app/report_aggregator.py
"""
Report Aggregator - Gathers operation data for PDF reports.

PERFORMANCE: Uses data_svc internal queries (5-10ms per query)
instead of HTTP API calls (150ms per call).
"""

class ReportAggregator:
    def __init__(self, data_svc, log):
        """
        Initialize aggregator with Caldera data service.
        
        Args:
            data_svc: Caldera's data service (internal database access)
            log: Logger instance
        """
        self.data_svc = data_svc
        self.log = log
    
    async def get_operation_data(self, operation_id):
        """
        Gather operation data using internal data_svc.
        
        Fast path: Direct database queries, no HTTP overhead.
        
        Args:
            operation_id (str): Operation UUID
        
        Returns:
            dict: {
                'operation': Operation object,
                'links': List of Link objects,
                'agents': List of Agent objects,
                'facts': List of Fact objects
            }
        
        Performance: ~30-40ms total (vs 600ms with HTTP)
        """
        # ‚úÖ Query 1: Get operation (5-10ms)
        operations = await self.data_svc.locate('operations', {'id': operation_id})
        
        if not operations:
            self.log.warning(f'Operation not found: {operation_id}')
            return None
        
        operation = operations[0]
        
        # ‚úÖ Query 2: Links already attached to operation.chain
        # No separate query needed! (0ms)
        links = operation.chain
        
        # ‚úÖ Query 3: Get unique agents from links (10-15ms)
        agents = []
        seen_paws = set()
        
        for link in links:
            if link.paw not in seen_paws:
                seen_paws.add(link.paw)
                agent_list = await self.data_svc.locate('agents', {'paw': link.paw})
                if agent_list:
                    agents.append(agent_list[0])
        
        # ‚úÖ Query 4: Facts from links (5-10ms)
        facts = []
        for link in links:
            if hasattr(link, 'facts') and link.facts:
                facts.extend(link.facts)
        
        self.log.debug(
            f'Aggregated data for {operation.name}: '
            f'{len(links)} links, {len(agents)} agents, {len(facts)} facts'
        )
        
        return {
            'operation': operation,
            'links': links,
            'agents': agents,
            'facts': facts
        }
```

**Option B: If aggregation is inline in `pdf_generator.py`:**

Find the section where you fetch data and replace HTTP calls:

```python
# plugins/reporting/app/pdf_generator.py

class PDFGenerator:
    def __init__(self, services):
        self.data_svc = services.get('data_svc')  # ‚Üê Add this
        self.log = services.get('logger')
        # ... rest of __init__
    
    async def generate(self, operation):
        """Generate PDF report."""
        
        # ‚ùå OLD WAY (SLOW):
        # async with aiohttp.ClientSession() as session:
        #     async with session.get(f'http://localhost:8888/api/v2/operations/{operation.id}') as resp:
        #         operation_data = await resp.json()
        
        # ‚úÖ NEW WAY (FAST):
        # Operation object already has all data!
        links = operation.chain  # List of Link objects
        
        # Get agents (if needed)
        agents = []
        for link in links:
            agent_list = await self.data_svc.locate('agents', {'paw': link.paw})
            if agent_list:
                agents.append(agent_list[0])
        
        # Now use links and agents for PDF generation
        # ... rest of PDF generation code
```

**Step 3: Update Service Initialization** (15 min)

Ensure `data_svc` is passed to your aggregator:

```python
# plugins/reporting/app/report_svc.py

class ReportService:
    def __init__(self, services):
        self.services = services
        self.data_svc = services.get('data_svc')  # ‚Üê Already have this
        self.log = services.get('logger')
        
        # Initialize PDF generator with services (includes data_svc)
        self.pdf_generator = PDFGenerator(services)  # ‚Üê Pass full services dict
        
        # Or if using separate aggregator:
        self.aggregator = ReportAggregator(self.data_svc, self.log)
        
        # ... rest of __init__
```

**Step 4: Test Performance** (15 min)

```bash
# Start Caldera
python server.py --insecure

# Create operation, run 10 techniques, stop

# Check logs for generation_time_ms
tail -f logs/caldera.log | grep "generation_time_ms"

# Expected improvement:
# Before: generation_time_ms: 5200 (5.2s)
# After:  generation_time_ms: 3800 (3.8s)
# Savings: 1.4s (27% faster)
```

**Step 5: Commit Changes**

```bash
git add plugins/reporting/app/
git commit -m "perf(reporting): optimize data gathering with data_svc

- Replace HTTP API calls with internal data_svc queries
- Reduce overhead from 600ms to 30ms (20x faster)
- Generation time drops from ~5.2s to ~3.8s
- Fixes: #2 Critical blocker (performance)"

git push origin develop
```

***

### **Success Criteria**

- ‚úÖ No `aiohttp.get` or `requests.get` in reporting code
- ‚úÖ Uses `await self.data_svc.locate(...)` for queries
- ‚úÖ Generation time <4s for 10-technique operations
- ‚úÖ Logs show 1.4s+ performance improvement

***

# üö® CRITICAL BLOCKER #3: SECURITY RISK - GITHUB PUBLISHING

## ‚ùå PROBLEM

**Symptom:** Your code uploads client PDF reports to public GitHub Pages.

**Root Cause:**  
You implemented a GitHub publishing feature that pushes reports to a public repository. **This is a severe security violation.**

**Why It's Dangerous:**
1. **Client Confidentiality Breach:** PDFs contain:
   - Client company names (Triskele's customers)
   - Discovered vulnerabilities
   - Internal IP addresses/hostnames
   - Attack techniques used
   
2. **Compliance Violations:**
   - NDA breach (Triskele's client contracts)
   - GDPR violations (EU clients)
   - SOC 2 violations (security posture)
   
3. **Reputational Damage:**
   - Clients lose trust in Triskele
   - Competitors access purple team techniques
   - Search engines index sensitive data

**Current (Dangerous) Code:**
```python
# plugins/orchestrator/app/webhook_service.py
class ConsolidatedWorkflowService:
    async def publish_to_github_pages(self, pdf_path):
        # ‚ùå Uploads to public GitHub repo
        # ‚ùå PDF contains client vulnerabilities
        # ‚ùå Violates NDA and compliance
```

***

## ‚úÖ SOLUTION: DELETE GITHUB PUBLISHING

### **What to Do:** Remove all GitHub publishing code immediately

**Step 1: Find GitHub Publishing Code** (5 min)

```bash
cd ~/caldera/plugins/orchestrator
grep -rn "github\|publish_to_github" app/

# Likely locations:
# - app/webhook_service.py
# - app/consolidated_workflow.py
```

**Step 2: Delete GitHub Publishing** (15 min)

Open the file and **delete these sections**:

```python
# ‚ùå DELETE THESE METHODS:
# - publish_to_github_pages()
# - push_to_github()
# - create_github_commit()
# - Any method with "github" in the name

# ‚ùå DELETE THESE IMPORTS:
# import github  # PyGithub library
# import git     # GitPython library

# ‚ùå DELETE THESE CONFIG VARIABLES:
# GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')
# GITHUB_REPO = os.getenv('GITHUB_REPO')
# GITHUB_BRANCH = 'gh-pages'
```

**Example of what to remove:**

```python
# BEFORE (DELETE THIS):
class ConsolidatedWorkflowService:
    async def run_workflow(self, operation_id):
        # ... other code ...
        
        # ‚ùå DELETE THIS ENTIRE SECTION ‚¨áÔ∏è
        # Publish PDF to GitHub Pages
        if pdf_path:
            try:
                await self.publish_to_github_pages(pdf_path)
                self.log.info('‚úÖ PDF published to GitHub Pages')
            except Exception as e:
                self.log.error(f'GitHub publishing failed: {e}')
        # ‚ùå DELETE ABOVE ‚¨ÜÔ∏è
    
    # ‚ùå DELETE THIS ENTIRE METHOD ‚¨áÔ∏è
    async def publish_to_github_pages(self, pdf_path):
        """Upload PDF to GitHub Pages."""
        import github
        g = github.Github(self.github_token)
        repo = g.get_repo(self.github_repo)
        # ... upload logic ...
    # ‚ùå DELETE ABOVE ‚¨ÜÔ∏è
```

**AFTER (Clean):**

```python
class ConsolidatedWorkflowService:
    async def run_workflow(self, operation_id):
        # Tag ELK alerts
        await self.tag_elk_alerts(operation_id)
        
        # Generate PDF
        pdf_path = await self.generate_pdf(operation_id)
        
        # ‚úÖ Store locally only (secure)
        if pdf_path:
            self.log.info(f'‚úÖ PDF saved locally: {pdf_path}')
            # PDF stays on TL VM (not published externally)
        
        # Send Slack notification (optional)
        await self.send_slack_notification(operation_id)
```

**Step 3: Remove GitHub Dependencies** (5 min)

```bash
# Remove from requirements.txt (if present)
cd ~/caldera
vim requirements.txt

# Delete these lines if present:
# PyGithub==1.59.0
# GitPython==3.1.40

# Uninstall from environment
pip uninstall -y PyGithub GitPython
```

**Step 4: Update Configuration** (5 min)

```bash
# Remove GitHub config from .env files
cd ~/caldera/plugins/orchestrator
vim .env

# Delete these lines:
# GITHUB_TOKEN=ghp_xxxxxxxxxxxx
# GITHUB_REPO=L1quidDroid/reports
# GITHUB_BRANCH=gh-pages

# Remove from .env.example too
vim .env.example
# (delete same lines)
```

**Step 5: Document Secure Alternative** (10 min)

Add comment in code explaining security decision:

```python
# plugins/orchestrator/app/webhook_service.py

class ConsolidatedWorkflowService:
    async def run_workflow(self, operation_id):
        """
        Automated workflow for operation completion.
        
        Security Note:
            PDFs are stored ONLY on the local TL VM filesystem.
            External publishing (GitHub Pages, cloud storage) is disabled
            to protect client confidentiality and comply with NDAs.
            
            Reports location: plugins/reporting/data/reports/
            Access: Triskele team only (TL VM access required)
        """
        # ... workflow code ...
```

**Step 6: Commit Removal**

```bash
git add plugins/orchestrator/app/webhook_service.py
git add requirements.txt .env.example
git commit -m "security: remove GitHub Pages publishing (client confidentiality)

- Deleted publish_to_github_pages() method
- Removed PyGithub and GitPython dependencies
- PDFs now stored locally on TL VM only
- Complies with client NDAs and SOC 2 requirements
- Fixes: #3 Critical blocker (security risk)"

git push origin develop
```

***

### **Success Criteria**

- ‚úÖ No `github`, `git`, or `publish_to_github` in code
- ‚úÖ No PyGithub or GitPython in requirements.txt
- ‚úÖ No GITHUB_TOKEN in .env files
- ‚úÖ PDFs stored only in `plugins/reporting/data/reports/`
- ‚úÖ Code comments document security rationale

***

# üìÖ WEEK 7 DAILY SCHEDULE

## **MONDAY EVENING (Today, 6:30 PM - 9:00 PM) - 2.5 hours**

### **Priority: Security + Cleanup**

**6:30 PM - 7:00 PM: Security Fix (30 min)**
```bash
# Task: Delete GitHub publishing
cd ~/caldera/plugins/orchestrator/app
vim webhook_service.py
# Delete publish_to_github_pages() method
# Delete GitHub imports
# Commit: "security: remove GitHub Pages publishing"
```

**7:00 PM - 7:30 PM: Verification Script (30 min)**
```bash
# Task: Run verification
cd ~/Internship_C
./verification_v2.sh  # From earlier in conversation
# Fix any errors found
```

**7:30 PM - 8:00 PM: Python 3.12 Fix (30 min)**
```bash
# Task: Fix datetime deprecation
cd plugins/enrollment/app
vim enrollment_service.py
# Replace: datetime.utcnow() ‚Üí datetime.now(timezone.utc)
# Commit: "fix: Python 3.12 compatibility"
```

**8:00 PM - 8:30 PM: Prune Bloat (30 min)**
```bash
# Task: Remove unused plugins
vim conf/local.yml
# Comment out: training, gameboard, sequencer
rm -rf plugins/sequencer  # If not using
# Commit: "chore: prune unused plugins"
```

**8:30 PM - 9:00 PM: Push All Changes (30 min)**
```bash
# Task: Push to GitHub
git status  # Review all changes
git push origin develop
# Verify on GitHub web interface
```

**‚úÖ Monday Deliverables:**
- ‚úÖ Security risk eliminated
- ‚úÖ Verification script passing
- ‚úÖ Python 3.12 compatible
- ‚úÖ RAM optimized

***

## **TUESDAY MORNING (9:00 AM - 12:00 PM) - 3 hours**

### **Priority: Critical Integration Fixes**

**9:00 AM - 10:00 AM: Orchestrator Hook (1 hour)**
```bash
# Task: Create hook.py
cd ~/caldera/plugins/orchestrator
touch hook.py
code hook.py
# Copy full implementation from BLOCKER #1 solution above
# Test: python server.py --insecure
# Verify logs: "Orchestrator: Registered operation.completed hook"
# Commit: "fix(orchestrator): integrate SIEM tagging into lifecycle"
```

**10:00 AM - 11:15 AM: Report Aggregator Optimization (1h 15min)**
```bash
# Task: Rewrite data gathering
cd ~/caldera/plugins/reporting/app
# Find HTTP calls: grep -n "aiohttp\|requests" *.py
vim report_aggregator.py  # Or pdf_generator.py
# Replace HTTP calls with data_svc.locate()
# Use implementation from BLOCKER #2 solution above
# Commit: "perf(reporting): optimize data gathering with data_svc"
```

**11:15 AM - 12:00 PM: Performance Testing (45 min)**
```bash
# Task: Validate improvements
python server.py --insecure
# Create operation with 10 techniques
# Stop operation
# Check logs:
tail -f logs/caldera.log | grep "generation_time_ms"
# Expected: <4000ms (was ~5200ms)
# If still slow, profile with cProfile
```

**‚úÖ Tuesday Morning Deliverables:**
- ‚úÖ Orchestrator auto-triggers tagging
- ‚úÖ Report generation <4s
- ‚úÖ Both critical fixes tested locally

***

## **TUESDAY AFTERNOON (1:00 PM - 3:00 PM) - 2 hours**

### **Priority: TL VM Deployment**

**1:00 PM - 2:00 PM: Deploy to Production (1 hour)**
```bash
# Task: Deploy to TL VM
ssh tony@triskele-lab-vm

cd ~/caldera
git pull origin develop

# Install dependencies (if any new ones)
source venv/bin/activate
pip install reportlab pillow psutil weasyprint

# Start Caldera
python server.py --insecure

# Watch logs for all plugins loading
tail -f logs/caldera.log | grep -E "orchestrator|reporting|enrollment"

# Expected:
# ‚úÖ Orchestrator plugin loaded successfully
# ‚úÖ Reporting plugin loaded successfully
# ‚úÖ Enrollment plugin loaded successfully (if you have one)
```

**2:00 PM - 3:00 PM: Integration Test on TL VM (1 hour)**
```bash
# Task: Test end-to-end workflow
# 1. Create operation "TL VM Test"
# 2. Run 5-10 techniques
# 3. Stop operation

# Monitor logs:
tail -f logs/caldera.log | grep -E "üè∑Ô∏è|‚úÖ"

# Expected output:
# üè∑Ô∏è Auto-tagging ELK alerts for operation: TL VM Test
# ‚úÖ ELK tagging complete
# üöÄ Auto-generating report for operation: TL VM Test
# ‚úÖ Auto-generated report: triskele_labs_tl_vm_test_20260106_140530.pdf (3.8KB, 3800ms)

# Verify PDF exists:
ls -lh plugins/reporting/data/reports/
# Should see new PDF file

# Open PDF and verify:
# - Triskele logo (if added)
# - Operation name correct
# - Techniques listed
# - No errors/corruptions
```

**‚úÖ Tuesday Afternoon Deliverables:**
- ‚úÖ Code deployed to TL VM
- ‚úÖ All plugins loading correctly
- ‚úÖ End-to-end workflow tested
- ‚úÖ PDF generates in <4s

***

## **WEDNESDAY (All Day, 9:00 AM - 5:00 PM) - 8 hours**

### **Priority: Demo Preparation**

**9:00 AM - 12:00 PM: Simplify PDF to One Page (3 hours)**

**Problem:** Your current PDF might be multi-page with too much detail for a 5-minute demo.

**Solution:** Create a minimal "demo mode" PDF with just essentials.

```python
# Task: Create simple PDF template
cd ~/caldera/plugins/reporting/app
vim pdf_generator.py

# Add this method:
def generate_simple_report(self, operation):
    """
    Generate one-page PDF for demos.
    
    Contents:
    1. Triskele logo (top)
    2. Operation name
    3. Success rate (e.g., "15/18 techniques succeeded (83%)")
    4. Duration (e.g., "Completed in 4m 32s")
    5. One table: Technique ID | Name | Status
    
    No detailed analysis (save for full report mode).
    Target: <50KB, 1 page, <2s generation.
    """
    from reportlab.lib.pagesizes import letter
    from reportlab.platypus import SimpleDocTemplate, Table, Paragraph, Spacer, Image
    from reportlab.lib.styles import getSampleStyleSheet
    
    # Create PDF
    output_path = Path(f"plugins/reporting/data/reports/demo_{operation.name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf")
    doc = SimpleDocTemplate(str(output_path), pagesize=letter)
    
    elements = []
    styles = getSampleStyleSheet()
    
    # 1. Logo (if exists)
    logo_path = Path("plugins/reporting/static/assets/triskele_logo.png")
    if logo_path.exists():
        logo = Image(str(logo_path), width=120, height=40)
        elements.append(logo)
        elements.append(Spacer(1, 20))
    
    # 2. Title
    title = Paragraph(f"<b>Purple Team Operation Report</b>", styles['Title'])
    elements.append(title)
    elements.append(Spacer(1, 10))
    
    # 3. Operation name
    op_name = Paragraph(f"Operation: <b>{operation.name}</b>", styles['Heading2'])
    elements.append(op_name)
    elements.append(Spacer(1, 10))
    
    # 4. Success rate
    total_links = len(operation.chain)
    successful_links = len([l for l in operation.chain if l.status == 0])
    success_rate = (successful_links / total_links * 100) if total_links > 0 else 0
    
    summary = Paragraph(
        f"<b>Success Rate:</b> {successful_links}/{total_links} techniques succeeded ({success_rate:.0f}%)",
        styles['Normal']
    )
    elements.append(summary)
    elements.append(Spacer(1, 10))
    
    # 5. Duration
    duration = operation.finish - operation.start if operation.finish else 0
    duration_str = f"{duration // 60}m {duration % 60}s"
    duration_para = Paragraph(f"<b>Duration:</b> {duration_str}", styles['Normal'])
    elements.append(duration_para)
    elements.append(Spacer(1, 20))
    
    # 6. Techniques table (simple)
    table_data = [['Technique ID', 'Name', 'Status']]
    for link in operation.chain[:10]:  # Limit to first 10 for demo
        status = '‚úÖ Success' if link.status == 0 else '‚ùå Failed'
        table_data.append([
            link.ability.technique_id,
            link.ability.name[:40],  # Truncate long names
            status
        ])
    
    table = Table(table_data, colWidths=[100, 300, 80])
    table.setStyle([
        ('BACKGROUND', (0, 0), (-1, 0), '#0f3460'),  # Triskele blue header
        ('TEXTCOLOR', (0, 0), (-1, 0), 'white'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 12),
        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
        ('GRID', (0, 0), (-1, -1), 1, 'black')
    ])
    elements.append(table)
    
    # Build PDF
    doc.build(elements)
    
    return output_path

# Update generate() to use simple mode for demos:
def generate(self, operation):
    """Generate PDF (simple mode for demos, full mode for production)."""
    demo_mode = os.getenv('REPORT_DEMO_MODE', 'false').lower() == 'true'
    
    if demo_mode:
        return self.generate_simple_report(operation)
    else:
        return self.generate_full_report(operation)  # Your existing logic
```

```bash
# Set demo mode in .env
cd ~/caldera/plugins/reporting
vim .env
# Add: REPORT_DEMO_MODE=true

# Test simple PDF
python server.py --insecure
# Run operation, check PDF is 1 page only
```

**12:00 PM - 1:00 PM: Lunch Break**

**1:00 PM - 3:00 PM: Create Demo Operations (2 hours)**

```bash
# Task: Pre-configure 3 demo operations

# In Caldera GUI:
# 1. Create "Tahsinur Demo - Discovery" (5 techniques)
#    - T1082: System Information Discovery
#    - T1016: System Network Configuration Discovery
#    - T1033: System Owner/User Discovery
#    - T1057: Process Discovery
#    - T1083: File and Directory Discovery

# 2. Create "Tahsinur Demo - Credential Access" (8 techniques)
#    - T1003: OS Credential Dumping
#    - T1555: Credentials from Password Stores
#    - ... (add more as available)

# 3. Create "Tahsinur Demo - Mixed Tactics" (12 techniques)
#    - Mix of Discovery, Credential Access, Lateral Movement

# For each:
# - Save as adversary profile
# - Run once to verify all techniques execute
# - Check PDF generates correctly
# - Note any failures to fix
```

**3:00 PM - 5:00 PM: Demo Script & Dry Runs (2 hours)**

```markdown
# Save as: demo_script_friday.md

# üéØ FRIDAY DEMO SCRIPT FOR TAHSINUR

## Setup (30 seconds)

**Terminal 1:** Logs
```bash
tail -f logs/caldera.log | grep -E "üè∑Ô∏è|üöÄ|‚úÖ|generation_time_ms"
```

**Terminal 2:** File Manager
```bash
cd plugins/reporting/data/reports
watch -n 1 ls -lh  # Auto-refresh every second
```

**Browser:** Caldera UI
```
http://localhost:8888
```

---

## Demo Flow (4 minutes)

### Part 1: The Problem (30 seconds)

**SAY:**
> "Historically, generating purple team reports took 50 seconds per operation:
> 1. Export operation as JSON (10s)
> 2. Upload to conversion tool (15s)
> 3. Wait for processing (20s)
> 4. Download PDF (5s)
> 
> That's 50 seconds of manual work per operation. For 20 operations per week, that's 16+ minutes of analyst time."

### Part 2: The Solution (3 minutes)

**SAY:**
> "I've automated this entire workflow. Watch:"

**DO:**
1. Show empty reports folder (Terminal 2)
2. Click operation "Tahsinur Demo - Discovery" in UI
3. Click "Start" ‚Üí techniques execute
4. **START TIMER** (show visible stopwatch)
5. Click "Stop" button

**POINT TO:**
- Terminal 1 logs appearing:
  ```
  üè∑Ô∏è Auto-tagging ELK alerts for operation: Tahsinur Demo - Discovery
  ‚úÖ ELK tagging complete for operation: Tahsinur Demo - Discovery
  üöÄ Auto-generating report for operation: Tahsinur Demo - Discovery (5 techniques)
  ‚úÖ Auto-generated report: triskele_labs_tahsinur_demo_discovery_20260109_100230.pdf (3.2KB, 3200ms)
  ```

- Terminal 2: PDF file appears
- **STOP TIMER** when PDF visible

**SAY:**
> "3.2 seconds total. Let me open the report."

**DO:**
6. Open PDF, show:
   - Triskele logo
   - Operation name
   - Success rate: "5/5 techniques succeeded (100%)"
   - Techniques table

### Part 3: Impact (30 seconds)

**SAY:**
> "Here's the impact:
> - Manual process: 50 seconds
> - Automated process: 3.2 seconds
> - **Time saved: 46.8 seconds per operation** (93% faster, 15.6x speedup)
> 
> For 20 operations per week:
> - Manual: 16.7 minutes/week
> - Automated: 1.1 minutes/week
> - **Weekly savings: 15.6 minutes** of analyst time freed up
> 
> Plus, ELK alerts are automatically tagged with operation context for threat hunting."

---

## Questions to Ask Tahsinur (30 seconds)

1. "Does this meet your expectations for automation?"
2. "What other tactics should we prioritize for demo operations?"
3. "Should we add email delivery for reports (auto-send to stakeholders)?"
4. "Any specific ELK fields you'd like tagged beyond what we're doing?"

---

## Return Offer Discussion (if time permits)

**SAY:**
> "I've really enjoyed solving these automation challenges for Triskele. This project‚Äîplus the agent enrollment one-liners and attack tagging‚Äîhave freed up significant team time. I'd love to continue this work as a graduate security engineer. Are you open to discussing a return offer?"

---

## Backup Plan (if demo fails)

**If PDF doesn't generate:**
- Show pre-generated PDF from Tuesday's test
- Walk through code in `pdf_generator.py` to explain logic
- Show logs from previous successful run

**If Caldera crashes:**
- Switch to home lab demo (screen share)
- Use pre-recorded video of working demo
- Show GitHub code review instead

---

## Post-Demo

**Send Slack message:**
```
Hey @Tahsinur! Thanks for the demo time today. Here's a summary:

‚úÖ Automated purple team workflow: SIEM tagging + PDF reports
‚úÖ 15.6x speedup: 50s ‚Üí 3.2s per operation
‚úÖ Weekly savings: 15.6 minutes of analyst time

Next steps:
- Extend to email delivery?
- Add more report types (executive summary, detailed analysis)?
- Integrate with ticketing system?

Code on GitHub: https://github.com/L1quidDroid/Internship_C/tree/develop

Let me know your feedback!
```
```

**Practice demo 3 times:**
```bash
# Dry run #1 (3:00 PM - 3:20 PM)
# - Time: Should be <5 minutes
# - Check: All logs appear correctly
# - Check: PDF generates
# - Note: Any glitches/issues

# Dry run #2 (3:30 PM - 3:50 PM)
# - Fix issues from run #1
# - Refine talking points
# - Test backup plan (if demo fails)

# Dry run #3 (4:00 PM - 4:20 PM)
# - Final polish
# - Should be smooth, confident
# - Record this run as backup video
```

**4:20 PM - 5:00 PM: Documentation**
```bash
# Update README with demo instructions
cd ~/caldera/plugins/reporting
vim README.md

# Add "Demo Mode" section
# Document REPORT_DEMO_MODE=true setting
# Include troubleshooting steps

git add README.md demo_script_friday.md
git commit -m "docs: add Friday demo script and demo mode instructions"
git push origin develop
```

**‚úÖ Wednesday Deliverables:**
- ‚úÖ One-page PDF template implemented
- ‚úÖ 3 demo operations created and tested
- ‚úÖ Demo script written and practiced 3 times
- ‚úÖ Backup plan prepared
- ‚úÖ Documentation updated

***

## **THURSDAY (Contingency Day, 9:00 AM - 1:00 PM) - 4 hours**

### **Priority: Polish & Bug Fixes**

**9:00 AM - 11:00 AM: Fix Issues from Dry Runs (2 hours)**

Common issues to watch for:

```bash
# Issue: PDF not generating
# Debug:
tail -f logs/caldera.log | grep "ERROR"
# Fix: Check report_svc.py error handling

# Issue: Slow generation (>5s)
# Debug:
grep "generation_time_ms" logs/caldera.log
# Fix: Profile with cProfile, optimize slow functions

# Issue: ELK tagging not working
# Debug:
grep "üè∑Ô∏è" logs/caldera.log
# Fix: Check orchestrator hook.py event subscription

# Issue: PDF corrupted
# Debug:
file plugins/reporting/data/reports/*.pdf
# Fix: Check WeasyPrint installation, test simple HTML first
```

**11:00 AM - 12:00 PM: Documentation Polish (1 hour)**

```bash
# Update all READMEs
cd ~/caldera

# Update orchestrator README
vim plugins/orchestrator/README.md
# Add: SIEM tagging workflow diagram
# Add: Troubleshooting section

# Update reporting README
vim plugins/reporting/README.md
# Add: Demo mode instructions
# Add: Performance benchmarks

# Update enrollment README (if exists)
vim plugins/enrollment/README.md
# Add: One-liner examples

git add */README.md
git commit -m "docs: polish documentation for Friday demo"
```

**12:00 PM - 1:00 PM: Final TL VM Test (1 hour)**

```bash
# SSH to TL VM
ssh tony@triskele-lab-vm

cd ~/caldera
git pull origin develop

# Clean slate test
rm -rf plugins/reporting/data/reports/*.pdf
python server.py --insecure

# Run all 3 demo operations
# Verify all PDFs generate correctly
# Check all logs show correct metrics

# If any issues, fix immediately
# This is your last chance before Friday!
```

**‚úÖ Thursday Deliverables:**
- ‚úÖ All bugs from dry runs fixed
- ‚úÖ Documentation polished
- ‚úÖ Final TL VM test passed
- ‚úÖ 100% confidence in Friday demo

***

## **FRIDAY (Demo Day, 10:00 AM) - 30 minutes**

### **9:30 AM: Pre-Demo Setup (30 min before)**

```bash
# On TL VM:
cd ~/caldera
python server.py --insecure

# Open terminals:
# Terminal 1: tail -f logs/caldera.log | grep -E "üè∑Ô∏è|üöÄ|‚úÖ"
# Terminal 2: cd plugins/reporting/data/reports && watch -n 1 ls -lh

# Browser: http://localhost:8888
# Load operations page

# Have stopwatch ready (phone or https://www.online-stopwatch.com/)

# Review demo script one last time
cat demo_script_friday.md
```

### **10:00 AM: Tahsinur Demo (5 min presentation + 5 min Q&A)**

Follow `demo_script_friday.md` exactly.

**Key Points to Emphasize:**
1. **Efficiency:** 15.6x speedup (50s ‚Üí 3.2s)
2. **Automation:** Zero manual work after setup
3. **Value:** 15.6 min/week freed for higher-value work
4. **Integration:** SIEM tagging + PDF reports in one workflow
5. **Production-ready:** Tested, documented, deployed

**After Demo:**
- Ask for feedback
- Gauge interest in return offer
- Send Slack summary (from demo script)

***

# üìä SUCCESS METRICS

## **Technical Metrics**

| Metric | Target | How to Verify |
|--------|--------|---------------|
| Orchestrator auto-tagging | 100% | Logs show "üè∑Ô∏è Auto-tagging..." on operation finish |
| PDF auto-generation | 100% | PDF appears in folder within 5s of operation stop |
| PDF is one page | 1 page | Open PDF, verify single page |
| Generation time | <4s | Logs show `generation_time_ms: <4000` |
| Demo duration | <5 min | Time from start to showing PDF |
| No errors during demo | 0 errors | No ERROR lines in logs during demo |
| Speedup achieved | >10x | Manual 50s / Automated <5s = >10x |

## **Career Metrics**

| Outcome | Evidence | Follow-up |
|---------|----------|-----------|
| Tahsinur impressed | Positive feedback during demo | Send thank-you Slack message |
| Return offer discussion | Tahsinur mentions extension/grad role | Prepare formal proposal with Triskele values |
| Team interest | Other team members ask about features | Document feature roadmap |
| Portfolio piece | Demo video recorded | Add to LinkedIn, resume |

***

# üö® TROUBLESHOOTING GUIDE

## **Problem: Orchestrator Hook Not Triggering**

**Symptoms:**
- Operation finishes, but no "üè∑Ô∏è Auto-tagging..." in logs
- ELK not getting tagged

**Debug:**
```bash
# Check hook loaded
grep "Orchestrator plugin loaded" logs/caldera.log

# Check event subscription
grep "Registered operation.completed hook" logs/caldera.log

# Check event_svc available
grep "event_svc not available" logs/caldera.log
```

**Fixes:**
1. **Hook not found:** Verify `plugins/orchestrator/hook.py` exists
2. **Event subscription failed:** Check Caldera version (needs 5.0.0+)
3. **event_svc missing:** Restart Caldera, check core plugins loaded

***

## **Problem: PDF Generation Slow (>5s)**

**Symptoms:**
- Logs show `generation_time_ms: >5000`
- Demo takes too long

**Debug:**
```bash
# Check for HTTP calls
grep -n "aiohttp\|requests" plugins/reporting/app/*.py

# Profile slow code
python -m cProfile -s cumtime server.py
```

**Fixes:**
1. **HTTP calls found:** Rewrite to use `data_svc.locate()` (see BLOCKER #2)
2. **WeasyPrint slow:** Switch to ReportLab (lighter)
3. **Too much data:** Limit to first 10 techniques in demo mode

***

## **Problem: PDF Not Generating**

**Symptoms:**
- Operation finishes, but no PDF in folder
- Logs show "Report generation failed"

**Debug:**
```bash
# Check output directory exists
ls -la plugins/reporting/data/reports/

# Check permissions
touch plugins/reporting/data/reports/test.txt

# Check disk space
df -h

# Check logs for errors
grep "Report generation" logs/caldera.log
```

**Fixes:**
1. **Directory missing:** `mkdir -p plugins/reporting/data/reports`
2. **Permission denied:** `chmod 755 plugins/reporting/data/reports`
3. **Disk full:** Free up space (check for old logs)
4. **WeasyPrint error:** Check dependencies (`pip install weasyprint`)

***

## **Problem: Caldera Crashes During Demo**

**Symptoms:**
- Server stops responding
- "unable to create thread" error

**Debug:**
```bash
# Check thread count
ps -T -p $(pgrep python) | wc -l

# Check memory
free -h
```

**Fixes:**
1. **Thread leak:** Verify singleton ThreadPoolExecutor in `report_svc.py`
2. **OOM:** Reduce report size, check memory limits
3. **Too many plugins:** Disable unused plugins in `conf/local.yml`

**Backup Plan:**
- Switch to home lab demo (screen share)
- Show pre-generated PDF + code walkthrough
- Use recorded demo video

***

# ‚úÖ FINAL CHECKLIST (Run Friday Morning)

```bash
# Friday 9:00 AM - Run this checklist

echo "üîç Pre-Demo Verification Checklist"
echo "===================================="

# 1. Code up-to-date
cd ~/caldera
git pull origin develop
echo "‚úÖ Code updated"

# 2. All plugins loading
python server.py --insecure &
sleep 10
if grep -q "Orchestrator plugin loaded" logs/caldera.log && \
   grep -q "Reporting plugin loaded" logs/caldera.log; then
    echo "‚úÖ All plugins loaded"
else
    echo "‚ùå Plugin loading failed - check logs!"
    exit 1
fi

# 3. Clear old reports
rm -f plugins/reporting/data/reports/*.pdf
echo "‚úÖ Old reports cleared"

# 4. Test operation exists
if curl -s http://localhost:8888/api/v2/operations | grep -q "Tahsinur Demo"; then
    echo "‚úÖ Demo operations exist"
else
    echo "‚ùå Demo operations missing - recreate them!"
    exit 1
fi

# 5. Demo mode enabled
if grep -q "REPORT_DEMO_MODE=true" plugins/reporting/.env; then
    echo "‚úÖ Demo mode enabled"
else
    echo "‚ö†Ô∏è Demo mode not set - PDF might be multi-page"
fi

# 6. Logs accessible
tail -1 logs/caldera.log > /dev/null
echo "‚úÖ Logs accessible"

# 7. Stopwatch ready
echo "‚è±Ô∏è Get stopwatch ready: https://www.online-stopwatch.com/"

echo ""
echo "===================================="
echo "‚úÖ Ready for demo!"
echo "Review demo script: cat demo_script_friday.md"
```

***

# üéâ POST-DEMO (Friday Afternoon)

## **After Demo:**

1. **Send Thank-You Message** (30 min)
```
# Slack to Tahsinur
Hey @Tahsinur! Thanks for the demo time today. Really appreciated your feedback on the automation workflow.

Summary:
‚úÖ SIEM tagging: Auto-triggers on operation completion
‚úÖ PDF reports: Generated in 3.2s (15.6x faster than manual)
‚úÖ Weekly impact: Saves 15.6 minutes of analyst time

Next steps based on your feedback:
- [Add items from demo discussion]

Looking forward to continuing this work‚Äîlet's chat about potential return offer soon!

Code: https://github.com/L1quidDroid/Internship_C
```

2. **Update GitHub** (30 min)
```bash
# Tag release
git tag -a v1.0-demo -m "Friday demo to Tahsinur - working automation"
git push origin v1.0-demo

# Update README with demo results
vim README.md
# Add: Demo results, performance metrics, feedback from Tahsinur
git commit -am "docs: add Friday demo results"
git push
```

3. **Document Lessons Learned** (1 hour)
```markdown
# Save as: lessons_learned_week7.md

# Week 7 Lessons Learned

## What Went Well
- [List successes]

## What Could Improve
- [List challenges]

## Technical Insights
- [List technical learnings]

## Next Steps
- [List follow-up items]
```

4. **Prepare Return Offer Proposal** (2 hours)
```markdown
# Save as: return_offer_proposal.md

# Graduate Security Engineer Proposal
**Tony To ‚Üí Triskele Labs**

## Achievements This Internship
1. Agent Enrollment: One-liner deployment (solves "No RDP")
2. Attack Tagging: SIEM integration (auto-tags ELK)
3. PDF Reporting: 15.6x automation speedup

## Value Add as Graduate Engineer
1. Continue automation initiatives
2. Extend to additional SIEM platforms
3. Build team training modules

## Proposed Timeline
- End internship: Feb 15, 2026
- Graduate role start: [Negotiate with Tahsinur]

## Compensation & Growth
- [Research AusSec grad ranges]
- [Career path: Grad ‚Üí Security Engineer ‚Üí Senior]
```

***

**You've got this! Follow this plan, fix the 3 blockers by Tuesday, and you'll deliver a killer demo on Friday. Good luck! üöÄ**

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/110672592/0fb653be-3e02-4316-9ce2-a6723fa10f2e/TL-Labs-Caldera-POC-REVISED-Implemen.txt)
[2](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/110672592/3a239338-72b4-41f9-9b7b-b7252b5bc819/copilot-response.txt)
[3](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/110672592/276c3f81-194e-4640-a1aa-080e809b3655/feature2.md)
[4](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/110672592/d5728765-f95d-490a-90a4-a82b7b3ab810/IMPLEMENTATION_SUMMARY_v1.1.md)